
\section{Introduction to Robotics}
\label{sec:robo-intro}
The last few years have seen an increasing research interest and results in the field of robotics. Robotics and solutions from this field of
research have pervaded almost every practical industry, ranging from extremely technical enterprises such as underwater and space exploration, to
everyday mundane tasks such as household cleaning, or driving cars, and consequently are steadily replacing error prone human 
intervention in these tasks. Earlier, they were largely restricted to working on assembly lines and industrial usage, where the tasks were
repetitive and uniform. Lately though, as a consequence of recent research, many successful robotic solutions have been deployed to address 
increasingly difficult tasks, many of them far more challenging than previously thought possible. The primary reason these tasks seem so
challenging is the uncertainty in an environment, which renders deterministic systems and solutions useless. There can be multiple causes for
uncertainty in any environment, and when it comes to robotics, it may be due to noise, precision of sensors, unpredictable events, or may even be 
due to inaccurate modeling of the world. All of these reasons contribute towards a huge bottleneck in the process of developing robust systems
and solutions across all domains. 

This problem of uncertainty, in particular, also affects the domain of autonomous navigation - the ability of a robot to navigate without external
aid - which is considered as the holy grail of mobile robotics. To be able to ``navigate'' in an environment, a robot must be able to ``see'' the 
world as we see it, which is to say, understand what are obstacles and what are paths, construct a map of its surroundings, 
recognize landmarks, move to a new location, and repeat the same process again. The term ``localization'' here is used broadly, meaning to 
achieve a sense of the world or
the map, and one's place (geographically) in it. One might even say, to move forward, one always needs to know where one is standing, and this 
this assessment of actual location, or current standing, is what we mean by localization. Early robotic systems relied on the usage 
of signalling, like
beacons and human operators, to localize themselves. Being inherently deterministic processes, they were unable to approach true autonomy in
any realistic scenario,
due to the restrictions and limitations placed by determinism and the problem of uncertainty in the environment. This led researchers to conclude
that robots needed a probabilistic model of information, and as a consequence, we see a paradigm shift in robotics research from deterministic
robotics to probabilistic robotics, ever since the mid 1990s. What it translates into, is that at any given point in time, a robot does not have
one deterministic answer for its location, but instead, has a guess - a set of point locations with a probability 
distribution, indicating the confidence with which it thinks it may be, in any of those locations - which can also be visualized as a point cloud.
This is known as a position estimate. Given
a model of the environment, and the ability to estimate it's location (referred to as localization), a robot may traverse any part of the map.
So the three things necessary for navigation are a model of the environment, a location estimate and a position estimate, which provide a
platform to make decisions on where to move, and the capacity to update all these three based on new perspectives, or rather, new sensor data
from the updated location.

\section{Problems in Robotics}
\label{sec:robo-problems}
Some of the problems tackled in mobile robotics research may be categorized as ``mapping'', and ``localization''. Mapping may be thought of
as the study of answering the first characteristic question, \emph{What does the world look like?}. It is answered by integrating the 
information assimilated by sensors into a model of the environment, and depicting that model by a representation. Some of the major challenges
in this field of study are representation of the environment, and interpretation of the sensor data.

In contrast to the field of Mapping, the research studies in Localization try to answer the second characteristic question \emph{Where am I?},
that is to say, estimating the location and pose of the robot, given a map of the world as a frame of reference. Some of the solution strategies
are tracking, where the initial position of the robot is known, and global localization, in which no or only some a-priori knowledge of the 
environment and the starting position are given.

For true autonomy, one can see this becomes a chicken-and-egg problem: an unbiased map is needed for localization, while an accurate pose
estimate is needed to build that map. That is, a solid answer to one of the characteristic questions will give rise to accurate estimations
of the other, but an autonomous robot has a solid answer to neither one of the questions. This question is addressed in the field of study of 
SLAM, or Simultaneous Localization and Mapping, in which strategies are developed to reinforce guesstimates of both pose and world map, based on
the nature or characteristics of both the environment (unmanned aerial, underwater, indoors, traffic or terrain), and the sensing capabilities of
the robot (radar, visual, infrared, sonic, etc).

\section{Localization}
\label{sec:robo-local}
As we can see, localization is one of the fundamental fields of research in mobile robotics. The earliest approaches made use of signals as
beacons. The 1950s saw the development of the Automated Guided Vehicles (or AGVs), which were wire guided. They had a sensor attached to the 
bottom of the platform, and a wire was placed in a slot cut in the ground. The sensors would track the radio frequency waves emitted from the
wire, and this would help the AGV localize. Having to cut slots to place the wires would impede the flexibility in changing a course, and 
this restricted the AGVs to follow a fixed path, which had to be laid beforehand. Between the 1960s and the 1970s, the Space Race spurred 
research goals in robotics too, and as a consequence, robots such as the Stanford Cart, Shakey the robot and the Lunokhod 1 were developed. 
The Stanford Cart was able to follow a white line with a television camera, and was initially attached with a long wire to a mainframe
where the calculations were made, which was later replaced by a radio link. A human operator sitting at the mainframe would manually 
control the robot via a television feed. 


The AGVs evolved into the AGCs (Autonomous Guided Carts), which was simpler because they used magnetic tapes or coloured tapes, which incurred
far lesser overhead when paths had to be changed, and more importantly, did not have to be remotely controlled. Although AGCs were autonomous,
they did not truly use localization techniques, because the robots were not aware of their locations yet. It could be said that they were using 
primitive tracking techniques, although tracking itself later evolved into a whole subdomain of research. These AGCs, although still
limited by their line following, paved the way for future techniques and technologies by posing new challenges.

To move forward from the limitations of a line-following robot, a robot had to have an idea of how far and in which direction it was moving, 
say, from a given reference point. One intuitive way, called dead reckoning, stems from age old navigation methods, which says if you know
a previously determined position, and if you can estimate the speed, time, and direction of travel from that point, you can estimate your new
location. Techniques were devised to calculate the revolutions of the wheels, or to measure the force experienced during acceleration
(Inertial Navigation Systems), but these techniques suffered from the inherent drawbacks of dead reckoning - the accumulation of errors in
estimation was essentially unbounded. Based on these techniques, the first reliable localization system developed was based on beacons.
The beacons provided a reliable frame of reference, and their locations was imbedded as a priori knowledge within the robot. The robot was 
equipped with the suitable sensors, 


%The Lunokhod 1 had four television cameras, two antennas, an X-ray
%spectrometer and telescope, cosmic ray detectors and a laser device. It was able to relay back more than 20,000 TV images, around two hundred
%high resolution panoramas, and twenty five soil analyses, and travelled a total distance of 10,540 metres. While the Stanford Cart and the 
%Lunokhod 1 were controlled via remote relay, Shakey was the first robot that could reason about its own actions. 


\section{Global Localization}
\label{sec:robo-global}
